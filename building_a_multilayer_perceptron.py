# -*- coding: utf-8 -*-
"""Assignment: Building a Multilayer Perceptron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfEWx_USXqcHOBa0daJkQLqDH7fbDoA0
"""

#importing torch library
import torch

#creating a tensor
t1 = torch.tensor([1,2,3,4])
t2 = torch.tensor([[1,2,3,4],
                   [5,6,7,8],
                   [9,10,11,12]])

#seeing the shape of the tensors
print(t1.shape)
print(t2.shape)

t3 = torch.tensor([[1,2,3,4],
                   [5,6,7,8],
                   [9,10,11,12]])

#reshaping your tensor
print(t3.reshape(6,2))

#resizing your tensor
print(t3.resize(6,2))

#transpose your tensor
print(t3.transpose(1,0))

#basic mathematical operations on tensor

import torch

a = torch.tensor([1,2,3])
b = torch.tensor([4,5,6])

c=a+b

print(c)

print(torch.add(a,b))

#we have subtration, multiplication, divison, addition

#generating a tensor with random numbers
rand_t = torch.rand(2,2)
print(rand_t)

#filling a tensor with zeroes (empty tensor)
zero_t = torch.zeros(2,3)
print(zero_t)

#creating the tensors from other data types
import numpy as np

data1=[1,2,3,4,5,6]
data2=np.array([1.5,2.5,3.5,6.8,9.3,7.0,2.8])

print(type(data1))

t1=torch.tensor(data1)
t2=torch.Tensor(data1)
t3=torch.from_numpy(data2)

print("Tensor ", t1, "DataType: ", t1.dtype)
print("Tensor ", t2, "DataType: ", t2.dtype)
print("Tensor ", t3, "DataType: ", t3.dtype)







#Making a MLP with torch on  SALARY dataset

path = "https://raw.githubusercontent.com/Moulishankar10/Employee-Salary-Classification/main/data/salary.csv"

import pandas as pd
import torch
import torch.nn as nn #this is used for creating neural network
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from keras.utils import to_categorical
from sklearn.metrics import accuracy_score

salary = pd.read_csv(path)

salary

#splitting the data
X=salary.iloc[:,:-1]
y=salary.iloc[:,-1]

#Generating train and test sets
X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.2, random_state=42)

#Normalize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

#do the label encoding
encoder = LabelEncoder()
y_train = encoder.fit_transform(y_train)
y_test = encoder.transform(y_test)

#convert the target to one-hot encoding
y_train_onehot = to_categorical(y_train, num_classes=3)

#defining the neural network with Torch

class MLP(nn.Module):
  #create a class which is driven from the nn class of the torch
  def __init__(self, input_size, hidden_size, output_size):
    super(MLP, self).__init__()
    self.fc1 = nn.Linear(input_size, hidden_size)
    # self.dropout = nn.Dropout(p=0.5) trying to prevent test accuracy of 1.0
    self.fc2 = nn.Linear(hidden_size, output_size)

  def forward(self, x):
    x=F.relu(self.fc1(x))
    x=self.fc2(x)
    return x

print(type(X_train))

#converting numpy arrays to tensors  so torch can work with them
X_train_tensor = torch.from_numpy(X_train).float()
y_train_tensor = torch.from_numpy(y_train).long()

#initialize the model class
mlp = MLP(input_size=5, hidden_size=10, output_size=3)

#defining the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(mlp.parameters(), lr=0.01, weight_decay=0.01)

from torch.nn.modules import loss
#train the model on train data
num_epochs = 100
for epoch in range(num_epochs):
  optimizer.zero_grad() #this part reset the calculated gradient of previous calculation
  output = mlp(X_train_tensor)
  loss = criterion(output,y_train_tensor)
  #thi part is updating the weight to get into a good values to predict good
  loss.backward()
  optimizer.step()

#Evaluate our model
with torch.no_grad(): # while evaluating i do not want my layers to calculate gradient or anything
#and some stuff like dropout( you will learn later )will act differently based on situation
    #converting from numpy to tensor this time test part
    X_test_tensor = torch.from_numpy(X_test).float()
    y_test_tensor = torch.from_numpy(y_test).float()

    outputs = mlp(X_test_tensor) # sending the data model has not seen
    _ , predicted = torch.max(outputs.data, 1)

    accuracy = accuracy_score(y_test_tensor,predicted)
    print("test accuracy: ", accuracy)

